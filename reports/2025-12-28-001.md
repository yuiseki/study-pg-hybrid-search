# 実験レポート: 埋め込みモデル比較 (2025-12-28)

## 目的
PGroonga + pgvector を組み合わせたハイブリッド検索環境で、複数埋め込みモデルの検索性能を比較し、関連ラベルを記録して再現可能にする。

## 環境 / データ
- seed: `db/init/020_seed.sql`（10テーマ×季節表現、合計100ドキュメント）
- 埋め込みモデル（Ollama）: snowflake-arctic-embed:22m / nomic-embed-text:v1.5 / embeddinggemma:300m / snowflake-arctic-embed2:568m / qwen3-embedding:4b
- ベクトルは `scripts/embed_documents.py` で各100件ずつ再計算
- クエリとラベル: `evaluations/data.json`（cat, meal, catphrase, search, embed の計5件）
- recall@k と MRR は `evaluations/calc_metrics.py --k 3 5 10` で再計算

## 対象クエリ
| Slug | クエリ | 説明 |
| --- | --- | --- |
| cat_seed2 | 猫 | 猫関連文書の拾われ方を確認 |
| meal_seed2 | 食事 | 寿司/コーヒー/焙煎系 |
| catphrase_seed2 | 吾輩は猫である。名前はまだ無い。 | 文学フレーズ |
| search_seed2 | 探し物 | ハイブリッド検索メモ |
| embed_seed2 | 埋め込みベクトル | 技術ノート/embedding系 |

## 主要結果（recall@10 / MRR）
| モデル | 猫 | 食事 | 吾輩 | 探し物 | 埋め込みベクトル |
| --- | --- | --- | --- | --- | --- |
| snowflake-arctic-embed:22m (384d) | 0 / 0 | 0 / 0 | 0 / 0 | 1.0 / 1.0 | 0 / 0 |
| nomic-embed-text:v1.5 (768d) | 0 / 0 | 1.0 / 1.0 | 1.0 / 0.33 | 0 / 0 | 0 / 0 |
| embeddinggemma:300m (768d) | 1.0 / 1.0 | 1.0 / 1.0 | 1.0 / 1.0 | 1.0 / 1.0 | 1.0 / 1.0 |
| snowflake-arctic-embed2:568m (1024d) | 1.0 / 1.0 | 1.0 / 1.0 | 1.0 / 1.0 | 1.0 / 1.0 | 1.0 / 1.0 |
| qwen3-embedding:4b (2560d) | 1.0 / 1.0 | 0 / 0 | 1.0 / 1.0 | 1.0 / 1.0 | 1.0 / 1.0 |

- embeddinggemma:300m と snowflake-arctic-embed2:568m（＋qwen3-embedding:4b）は、5クエリすべてで recall@10=1.0 / MRR=1.0 を達成。小〜中規模の日本語コーパスに対し、比較的安定して relevant を上位に配置できた。
- snowflake 384d と nomic 768d は特定テーマ（散歩、公園、焙煎など）に偏り、猫・技術クエリでは relevant を拾えず recall=0。用途が限定される可能性がある。

## 再現手順
1. `make clean && make start` で DB を初期化
2. 全モデルで `scripts/embed_documents.py --model <name> --batch-size 16` を実行
3. `./evaluations/calc_metrics.py --k 3 5 10` で表と同じメトリクスを再生成
4. `evaluations/data.json` と `evaluations/labels_*.txt` を参照すれば、ラベル付きランキングをそのまま再利用できる

## 今後の課題
- クエリをさらに追加（温泉、自転車、AI など）し、ラベルを充実させてモデル間の傾向を詳細化する
- 100ドキュメントの seed を手動で多様化し、特定の系列に偏らない評価セットを構築する
- ハイブリッド検索（PGroonga + pgvector）の融合スコアについても同様にラベリングし、RRF 重みの最適化を検討する

