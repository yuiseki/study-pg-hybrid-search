# 実験レポート 2025-12-28-002: seed2 100件におけるハイブリッド検索評価

## 背景と目的
- PostgreSQL 17 + PGroonga + pgvector + Ollama を用いたローカル検証環境で、全文検索・ベクトル検索・RRFハイブリッドの性能を比較する再現実験を行った。
- 評価用データ（`evaluations/data.json`）には、`documents.source = 'seed2'` の100件に対し 24 クエリ（動物/食/都市/技術など）とユーザー付与の relevant doc_id が登録されている。
- 目的は、(1) モデル次元やアーキテクチャの違いが recall / MRR / nDCG にどう反映されるか、(2) PGroonga テキスト結果を RRF で混合する価値があるか、を第三者にも共有できる形で可視化すること。

## 実験方法
- コマンド: `make reset && make embed_all && make eval`
  - `make reset` で DB を再初期化し seed2 ドキュメントを投入。
  - `make embed_all` で Ollama 上の 5 モデル（384〜2560次元）により `document_embeddings` を全件再計算。
  - `make eval` が `evaluations/run_eval.py` を起動し、`text`/`vector`/`hybrid` を順に実行。PGroonga 側は `content &@~ q`、ベクトル側は halfvec + HNSW、ハイブリッドは RRF (k=60, 重み 1:1 / 2:1 / 1:2)。
  - 得られたランキングは `evaluations/out/2025-12-28T17-08-54/rankings.jsonl` に1条件1行で保存。
- メトリクス算出: `evaluations/calc_metrics.py --rankings <...>/rankings.jsonl`
  - 各条件の recall@3/5/10、MRR、nDCG@3/5/10 を計算し、`metrics.json` と `metrics.md` に出力。

## 主な結果（metrics.md から抜粋）
- テキスト単体（PGroonga）: `MRR=0.417`, `recall@10=0.417`。手動ラベルが「完全一致するフレーズ」中心のため、シンプルな unigram 検索では上位10件までの再現率が 40% 程度に留まった。
- ベクトル単体:
  - `embeddinggemma:300m` と `qwen3-embedding:4b` が同率首位 (`MRR=0.962`, `recall@10≈0.896〜0.900`, `nDCG@10≈0.94`)。モデル次元やパラメータ数が増えると長文・抽象クエリの拾い方が安定。
  - `snowflake-arctic-embed2:568m` は `MRR=0.900` と好成績だが、384次元モデル `snowflake-arctic-embed:22m` は `MRR=0.472` と大きく劣後。embedding の表現力不足がそのまま recall の差に現れた。
  - `nomic-embed-text:v1.5` は中間 (`MRR=0.767`)。特定カテゴリ（猫・自転車など）では十分だが、技術系クエリで relevant を落とすケースがある。
- ハイブリッド (RRF):
  - `embeddinggemma:300m`/`qwen3-embedding:4b` にテキストを足しても指標はほぼ等しく (`MRR=0.962`, `recall@10≈0.896`)、今回のデータセットではベクトル側がすでに十分に relevant を上位に並べている。
  - `nomic-embed-text:v1.5` では `text:vector=2:1` の重みで `recall@10=0.808` とわずかに改善。テキスト側のシグナルが不足している場合のみ RRF 調整の効果が見える。
  - `snowflake-arctic-embed:22m` もテキスト重視 (`2:1`) にすると `MRR=0.659` → `0.659` (維持) だが、vector重視 (`1:2`) では成績低下するなど、弱いベクトルモデルほど RRF パラメータの影響を受けやすい。

## 考察
- 24 クエリ中 20 件以上で relevant doc_id が 10 件設定されているため、`recall@10` が 0.9 近くまで達するモデルは「カテゴリ全体を漏れなく拾えている」と解釈できる。embeddinggemma と qwen3 は少ないパラメータでも安定して 0.9 以上を達成しており、seed2 スケールでは十分高性能。
- ハイブリッドがベクトル単体より優位になる場面は、テキスト側でのみ拾えるキーワード（例: 「夜の寿司屋」「真夜中の公園」など）と、ベクトル側が苦手なクエリが重なった場合に限られる。今後は PGroonga の tokenizer を変える、フレーズクエリを追加するなど、テキスト専用の強みを強化する必要がある。
- ベクトル次元と性能の関係: 384d → 768d で大幅にメトリクスが向上し、768d → 1024d/2560d ではさらに約 +0.15 MRR 向上。今回のサンプルでは「モデルサイズが大きいほど良い」が観察できたが、RRF 重み最適化や exact search との比較で recall を監視しないと、より難しいデータでは差が縮む可能性がある。

## 成果物
- ランキング: `evaluations/out/2025-12-28T17-08-54/rankings.jsonl`
- 実行設定: `evaluations/out/2025-12-28T17-08-54/run_config.json`
- メトリクス: `evaluations/out/2025-12-28T17-08-54/metrics.json`, `metrics.md`

## 次のアクション
1. テキスト検索の recall 向上策（PGroonga tokenizer変更、`literal`/`synonym` クエリ）を検討し、再度 RRF の寄与を測定。
2. クエリセットを 40 件規模に拡充し、カテゴリバランス（技術/雑記/感情表現など）を整える。
3. `run_eval.py` の `datetime.utcnow()` を timezone-aware API へ置き換え、DeprecationWarning を解消。
